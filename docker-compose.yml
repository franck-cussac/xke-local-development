version: '2.4'
services:
  postgres:
    image: postgres:9.6
    environment:
      - POSTGRES_USER=airflow
      - POSTGRES_PASSWORD=airflow
      - POSTGRES_DB=airflow

  airflow:
    image: puckel/docker-airflow:1.10.6
    restart: always
    depends_on:
      - postgres
      - spark-master
    environment:
      - EXECUTOR=Local
      - JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64
    volumes:
      - spark_jars:/spark/jars
      - spark_home:/spark/bin/
      - java_home:/usr/lib/jvm/java-8-openjdk-amd64
    ports:
      - 8080:8080
    command: webserver
    healthcheck:
      test: ["CMD-SHELL", "[ -f /usr/local/airflow/airflow-webserver.pid ]"]
      interval: 30s
      timeout: 30s
      retries: 3

  namenode:
    image: bde2020/hadoop-namenode:1.1.0-hadoop2.8-java8
    environment:
      - CLUSTER_NAME=test
    env_file:
      - ./hadoop.env
    ports:
      - 50070:50070
  datanode:
    image: bde2020/hadoop-datanode:1.1.0-hadoop2.8-java8
    depends_on:
      - namenode
    env_file:
      - ./hadoop.env
    ports:
      - 50075:50075

  spark-deploy-data:
    image: xke/spark-deploy-data
    depends_on:
      namenode:
        condition: service_healthy
      datanode:
        condition: service_healthy
    env_file:
      - ./hadoop.env

  spark-master:
    image: bde2020/spark-master:2.1.0-hadoop2.8-hive-java8
    hostname: spark-master
    ports:
      - 8888:8080
      - 7077:7077
    volumes:
      - spark_jars:/spark/jars
      - spark_home:/spark/bin/
      - java_home:/usr/lib/jvm/java-8-openjdk-amd64
    env_file:
      - ./hadoop.env

  spark-worker:
    image: bde2020/spark-worker:2.1.0-hadoop2.8-hive-java8
    depends_on:
      spark-master:
        condition: service_healthy
    environment:
      - SPARK_MASTER=spark://spark-master:7077
    ports:
      - 8081
    env_file:
      - ./hadoop.env

  hue:
    image: bde2020/hdfs-filebrowser:3.11
    ports:
      - 8088:8088
    environment:
      - NAMENODE_HOST=namenode

volumes:
  spark_home:
  java_home:
  spark_jars:
